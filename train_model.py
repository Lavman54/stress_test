import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

# ğŸ“Œ **1ï¸âƒ£ Veriyi YÃ¼kle ve Ã–n Ä°ÅŸlem Yap**
file_path = "/home/lavman/myenv/stress_detection_data_turkish.csv"
df = pd.read_csv(file_path)

# Hedef deÄŸiÅŸkeni belirleme
target_column = "Stres_Seviyesi"

# 'Yes' ve 'No' iÃ§eren sÃ¼tunlarÄ± sayÄ±ya Ã§evirelim
binary_columns = ["Sigara_KullanÄ±mÄ±", "Meditasyon_PratiÄŸi"]

for col in binary_columns:
    df[col] = df[col].replace({"Yes": 1, "No": 0})

# "Stres_Seviyesi"ni tamamen sayÄ±ya Ã§evirelim
df["Stres_Seviyesi"] = df["Stres_Seviyesi"].replace({"Low": 0, "Medium": 1, "High": 2}).astype(int)

# Saat formatÄ±ndaki sÃ¼tunlarÄ± belirleyelim
time_columns = ["Uyanma_Saati", "Yatma_Saati"]

# Saatleri dakikaya Ã§evirecek fonksiyon
def convert_time_to_minutes(time_str):
    try:
        hours, minutes = map(int, time_str[:-3].split(":"))
        if "PM" in time_str and hours != 12:
            hours += 12
        if "AM" in time_str and hours == 12:
            hours = 0
        return hours * 60 + minutes
    except:
        return None  # HatalÄ± deÄŸerler iÃ§in NaN dÃ¶ndÃ¼r

# Saat formatÄ±ndaki sÃ¼tunlarÄ± dÃ¶nÃ¼ÅŸtÃ¼r
for col in time_columns:
    df[col] = df[col].astype(str).apply(convert_time_to_minutes)

# Eksik verileri temizleyelim
df.dropna(inplace=True)

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenleri (X) ve hedef deÄŸiÅŸkeni (y) ayÄ±rma
X = df.drop(columns=[target_column])
y = df[target_column]

# Kategorik deÄŸiÅŸkenleri dÃ¶nÃ¼ÅŸtÃ¼r
X = pd.get_dummies(X, columns=["Cinsiyet", "Meslek", "Medeni_Durum", "Egzersiz_TÃ¼rÃ¼"], drop_first=True)

# Veriyi eÄŸitim ve test kÃ¼melerine ayÄ±r
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Veriyi Ã¶lÃ§eklendirme
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ğŸ“Œ **2ï¸âƒ£ PyTorch Ä°Ã§in Veriyi HazÄ±rla**
X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)
X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)

batch_size = 32
train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
test_dataset = TensorDataset(X_test_tensor, y_test_tensor)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# ğŸ“Œ **3ï¸âƒ£ GÃ¼ncellenmiÅŸ Model (Daha Derin, Daha Fazla NÃ¶ron, Optimize EdilmiÅŸ Dropout)**
class StressNet(nn.Module):
    def __init__(self):
        super(StressNet, self).__init__()
        self.fc1 = nn.Linear(X_train.shape[1], 256)
        self.bn1 = nn.BatchNorm1d(256)
        self.drop1 = nn.Dropout(0.2)

        self.fc2 = nn.Linear(256, 128)
        self.bn2 = nn.BatchNorm1d(128)
        self.drop2 = nn.Dropout(0.3)

        self.fc3 = nn.Linear(128, 64)
        self.bn3 = nn.BatchNorm1d(64)
        self.drop3 = nn.Dropout(0.3)

        self.fc4 = nn.Linear(64, 3)  # 3 sÄ±nÄ±f olduÄŸu iÃ§in 3 Ã§Ä±kÄ±ÅŸ
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = torch.relu(self.bn1(self.fc1(x)))
        x = self.drop1(x)

        x = torch.relu(self.bn2(self.fc2(x)))
        x = self.drop2(x)

        x = torch.relu(self.bn3(self.fc3(x)))
        x = self.drop3(x)

        x = self.softmax(self.fc4(x))
        return x

# ğŸ“Œ **4ï¸âƒ£ Modeli EÄŸit ve Kaydet**
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = StressNet().to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0005)  # Daha dÃ¼ÅŸÃ¼k Ã¶ÄŸrenme oranÄ±

num_epochs = 100  # Epoch sayÄ±sÄ±nÄ± artÄ±rdÄ±k
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    if (epoch + 1) % 10 == 0:
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}")

# Modeli kaydet
torch.save(model.state_dict(), "/home/lavman/myenv/stress_model.pth")
print("Model baÅŸarÄ±yla kaydedildi!")
